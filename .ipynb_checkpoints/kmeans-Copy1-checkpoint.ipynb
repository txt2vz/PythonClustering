{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9ec803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 documents\n",
      "3 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans, MiniBatchKMeans\n",
    "\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "data_folder = \"C:/Data/DataSetForPaper2023/crisis3\"\n",
    "dataset = sklearn.datasets.load_files(data_folder,  description=None, categories=None, load_content=True, shuffle=True, encoding='utf-8', decode_error='ignore', random_state=0)\n",
    "\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd59095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "tfidf vectorizer\n"
     ]
    }
   ],
   "source": [
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "\n",
    "print(\"tfidf vectorizer\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "            max_df=0.5,\n",
    "            max_features= 2000, #10000,\n",
    "            min_df=2,\n",
    "            stop_words=\"english\",\n",
    "            use_idf= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9c1c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.044480s\n",
      "n_samples: 1500, n_features: 1331\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(dataset.data)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "numDocs = X.shape[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6023794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(max_iter=100, n_clusters=3, n_init=1, verbose=False)\n",
      "done in 0.162s\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(\n",
    "            n_clusters=true_k,\n",
    "            init=\"k-means++\",\n",
    "            max_iter=100,\n",
    "            n_init=1,\n",
    "            verbose= False  \n",
    "        )\n",
    "\n",
    "#print(\"kMeans ++ run number: \" + str(i))\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f33bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-measure: 0.362\n",
      "Homogeneity: 0.309\n",
      "Completeness: 0.437\n",
      "Adjusted Rand: 0.166\n"
     ]
    }
   ],
   "source": [
    "v = metrics.v_measure_score(labels, km.labels_)\n",
    "h = metrics.homogeneity_score(labels, km.labels_)\n",
    "c = metrics.completeness_score(labels, km.labels_)\n",
    "adjustedRand = metrics.adjusted_rand_score(labels, km.labels_)\n",
    "\n",
    "print(\"V-measure: %0.3f\" % v)\n",
    "print(\"Homogeneity: %0.3f\" % h)\n",
    "print(\"Completeness: %0.3f\" % c)\n",
    "print(\"Adjusted Rand: %0.3f\" % adjustedRand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e95e566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath = \"resultsKmeans.csv\"\n",
    "resultsFile = open(filePath, \"a\")\n",
    "\n",
    "if os.path.getsize(filePath) == 0:\n",
    "  resultsFile.write(\"index, v, h, c, adjustRand, numDocs \\n\")\n",
    "\n",
    "resultsFile.write(\"crisis3 \" + \", \" + str(v) +  \", \" + str(h) + \", \" + str(c) +  \", \" + str(adjustedRand) + \", \" + str(numDocs) + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ee8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694f41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1dd2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
